{"cells":[{"metadata":{},"cell_type":"markdown","source":"#             Exploratory Data Analysis of Car Features"},{"metadata":{},"cell_type":"markdown","source":"# Context\nAs a data scientist, the majority of your time will be spent on data pre-processing i.e.\nmaking sure you have the right data in the right format. Once this is done, you get a\nsense of your dataset through applying some descriptive statistics and then, you move\non to the exploration stage wherein you plot various graphs and mine the hidden\ninsights. In this project, you as a data scientist are expected to perform Exploratory data\nanalysis on how the different features of a car and its price are related. The data comes\nfrom the Kaggle dataset \"Car Features and MSRP\". It describes almost 12,000 car\nmodels, sold in the USA between 1990 and 2017, with the market price (new or used)\nand some features.\n\n# Objective\nThe objective of the project is to do data pre-processing and exploratory data analysis\nof the dataset.\n\n\n# Data Description\n Make Car Make\n Model Car Model\n Year Car Year (Marketing)\n Engine Fuel Type Engine Fuel Type\n Engine HP Engine HorsePower (HP)\n Engine Cylinders Engine Cylinders\n Transmission Type Transmission Type\n Driven_Wheels Driven Wheels\n Number of Doors Number of Doors\n Market Category Market Category\n Vehicle Size Size of Vehicle\n Vehicle Style Type of Vehicle\n highway MPG Highway MPG\n city mpg City MPG\n Popularity Popularity (Twitter)\n MSRP Manufacturer Suggested Retail Price\n \n \n#  Steps\n1. Import the dataset and the necessary libraries, check datatype, statistical summary,\nshape, null values etc.\n2. Are there any columns in the dataset which you think are of less relevance. If so, give\nyour reasoning and drop them.\n3. Rename the columns \"Engine HP\": \"HP\", \"Engine Cylinders\": \"Cylinders\", \"Transmission\nType\": \"Transmission\", \"Driven_Wheels\": \"Drive Mode\",\"highway MPG\": \"MPG-H\", \"city\nmpg\": \"MPG-C\", \"MSRP\": \"Price\"\n4. Check for any duplicates in the data, check for null values and missing data and remove\nthem.\n5. Plot graphs of various columns to check for outliers and remove those data points from the\ndataset.\n6. What car brands are the most represented in the dataset and find the average price among\nthe top car brands.\n7. Plot the correlation matrix and document your insights.\n8. Perform EDA and plot different graphs and document your findings (Try to see how other\nvariables affect the price of the car)\n9. (Extra Credits)Split the dataset into 80 and 20 ratio and build a machine learning model with\nPrice as the target variable\n10. (Extra Credits)Try different algorithms and check their performance over metrics like R\nsquare, RMSE, MAE etc and document your findings"},{"metadata":{},"cell_type":"markdown","source":"# 1. Import the dataset and the necessary libraries, check datatype, statistical summary,shape, null values etc.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing the required librarirs\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns            #visualization\nimport matplotlib.pyplot as plt  #visualization\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reading the dataset\n\ncar_df=pd.read_csv(\"../input/datacsv/data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Printing the first five rows using the HEAD() function\n\ncar_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#printing the last 5 lines of the dataset using TAIL() function\n\ncar_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data Types\n\ncar_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#shape\n\ncar_df.mean().shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#NULL values\n\ncar_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#printing all the information of the dataset to know how it is\n\ncar_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The describe() method is used for calculating some statistical data like percentile,mean,std\n#It analyzes both numeric and object series and also the DataFrame column sets of mixed data types\"\"\"\"\n\ncar_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Are there any columns in the dataset which you think are of less relevance. If so, give your reasoning and drop them.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#By observing the car_data.info()\n\ncar_df=car_df.drop(['Engine Fuel Type','Number of Doors','Market Category'],axis=1)\ncar_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3.Rename the columns \"Engine HP\": \"HP\", \"Engine Cylinders\": \"Cylinders\", \"TransmissionType\": \"Transmission\", \"Driven_Wheels\": \"Drive Mode\",\"highway MPG\": \"MPG-H\", \"citympg\": \"MPG-C\", \"MSRP\": \"Price\"\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Renaming Columns and Replicating Data \n\ncar_df.rename(columns = { 'Engine HP': 'HP'}, inplace = True)\ncar_df.rename(columns = { 'Engine Cylinders': 'Cylinders'}, inplace = True)\ncar_df.rename(columns = { 'Transmission Type': 'Transmission'}, inplace = True)\ncar_df.rename(columns = { 'Driven_Wheels': 'Drive Mode'}, inplace = True)\ncar_df.rename(columns = { 'highway MPG': 'MPG-H'}, inplace = True)\ncar_df.rename(columns = { 'city mpg': 'MPG-C'}, inplace = True)\ncar_df.rename(columns = { 'MSRP': 'Price'}, inplace = True)\ncar_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Check for any duplicates in the data, check for null values and missing data and remove them.\n "},{"metadata":{"trusted":true},"cell_type":"code","source":"duplicated_rows_car_df=car_df[car_df.duplicated()]\nprint(\"Number of dupliacted rows are:\",duplicated_rows_car_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car_df=car_df.drop_duplicates()\ncar_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#isnull(). sum() will give the column-wise sum of missing values. \n#This returns the counts of non-NA, NA and total number of entries per group.\n\nprint(car_df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car_df=car_df.dropna() #dropping the missing values\ncar_df.count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Plot graphs of various columns to check for outliers and remove those data points from the dataset.\n "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=car_df['Price'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=car_df['HP'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=car_df['Cylinders'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The quantile() function is used to get values at the given quantile over requested axis. \n#Value between 0 <= q <= 1, the quantile(s) to compute.\n#Equals 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n\nQ1=car_df.quantile(0.25)\nQ3=car_df.quantile(0.75)\nIQR=Q3-Q1\nprint(IQR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car_df=car_df[~((car_df<(Q1-1.5*IQR)) |(car_df>(Q3+1.5*IQR))).any(axis=1)]\ncar_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. What car brands are the most represented in the dataset and find the average price among the top car brands"},{"metadata":{"trusted":true},"cell_type":"code","source":"#finding the percentage of car per brand \ncounts=car_df['Make'].value_counts()*100/sum(car_df['Make'].value_counts())\n\n\n#10 car brands which are in top most position\npopular_labels=counts.index[:10]\n\n#plot\nplt.figure(figsize=(10,5))\nplt.barh(popular_labels,width=counts[:10])\nplt.title('TOP 10 CAR BRANDS')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prices=car_df[['Make','Price']].loc[(car_df['Make']=='Chevrolet') |\n                                    \n                                    (car_df['Make']=='Ford') |\n                                   (car_df['Make']=='Volkswagen') |\n                                   (car_df['Make']=='Toyota') |\n                                   (car_df['Make']=='Dodge') |\n                                   (car_df['Make']=='Nissan') |\n                                   (car_df['Make']=='GMC') |\n                                   (car_df['Make']=='Honda') |\n                                   (car_df['Make']=='Mazda')].groupby('Make').mean()\nprint(prices)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Plot the correlation matrix and document your insights.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"car_df.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"HIGH CORRELATION BETWEEN   --- Cylinders & HP , Highway mpg & City mpg\nHIGH ANTICORRELATION       --- Cylinders & highway mpg "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nc=car_df.corr()\nsns.heatmap(c,cmap=\"Blues\",annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 8. Perform EDA and plot different graphs and document your findings (Try to see how other variables affect the price of the car)"},{"metadata":{},"cell_type":"markdown","source":"*SCATTER PLOT*"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax=plt.subplots(figsize=(10,6))\nax.scatter(car_df['HP'],car_df['Price'])\nax.set_xlabel('HP')\nax.set_ylabel('Price')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#which vehicle style segment of cars sold the most\n\ncar_df['Vehicle Style'].value_counts().plot.bar(figsize=(10,6))\nplt.title(\"CARS SOLD BY BODY\")\nplt.ylabel('number of vehicles')\nplt.xlabel('Body type');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **sedan cars were sold most  cars followed by 4dr SUV **"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y='Vehicle Style',data=car_df,hue='Drive Mode')\nplt.title(\"Vehicle Typev/s Drive mode Type\")\nplt.ylabel('Vehicle Type')\nplt.xlabel('Count of vehicle')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# making a new group \"Price_group\""},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating a new column 'Price_group and assigning the value based on price of the car\n\ncar_df['Price_group']=pd.cut(car_df['Price'],[0,20000,40000,60000,80000,100000,600000],\n                             labels=['<20K','20-39K','40-59K','6-079K','80-99K','>100K'],include_lowest=True)\ncar_df['Price_group']=car_df['Price_group'].astype(object)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(car_df['Price_group'].value_counts()/len(car_df)*100).plot.bar(figsize=(10,6))\nplt.title(\"Price group bar diagram\")\nplt.ylabel('% of vehicles')\nplt.xlabel('Price group')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 9. (Extra Credits)Split the dataset into 80 and 20 ratio and build a machine learning model with Price as the target variable"},{"metadata":{},"cell_type":"markdown","source":"# Implementing the different machine learning models like -linear Regression  and predicting the values"},{"metadata":{"trusted":true},"cell_type":"code","source":"X =car_df[['Popularity','Year','HP','Cylinders','MPG-H','MPG-C']].values\ny=car_df['Price'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature scaling \n\nfrom sklearn.preprocessing import StandardScaler\nsc_X=StandardScaler()  \nsc_y=StandardScaler()\nX=sc_X.fit_transform(X)\ny=sc_y.fit_transform(y.reshape(-1,1))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#splitting the dataset into TRAINING set & TESTING set\n\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#as we discussed above fitting the multiple linear regression to the training set\n\nfrom sklearn.linear_model import LinearRegression\nregressor=LinearRegression()\nregressor.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#here we  are predicting the TEST SET results\n\ny_pred=regressor.predict(X_test)\nplt.scatter(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot((y_test-y_pred),bins=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nprint('Mean Absolute Error:',metrics.mean_absolute_error(y_test,y_pred))\nprint('Root mean Squared Error:',np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\nprint('R2 Score:',metrics.r2_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 10. (Extra Credits)Try different algorithms and check their performance over metrics like R square, RMSE, MAE etc and document your findings"},{"metadata":{"trusted":true},"cell_type":"code","source":"#fitting the POLYNOMIAL REGRESSION  to this dataset\n\nfrom sklearn.preprocessing import PolynomialFeatures\npoly_reg=PolynomialFeatures(degree=4)\nX_poly=poly_reg.fit_transform(X_train)\npoly_reg.fit(X_poly,y_train)\nlin_reg_2=LinearRegression()\nlin_reg_2.fit(X_poly,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predicting the new result using the polynomial regression \n\ny_pred=lin_reg_2.predict(poly_reg.fit_transform(X_test))\nplt.scatter(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot((y_test-y_pred),bins=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mean Absolute Error:',metrics.mean_absolute_error(y_test,y_pred))\nprint('Root mean Squared Error:',np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\nprint('R2 Score:',metrics.r2_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fitting the SVR to this dataset\n\nfrom sklearn.svm import SVR\nregressor=SVR(kernel='rbf')\nregressor.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predicting new result \n\ny_pred=regressor.predict(X_test)\nplt.scatter(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot((y_test-y_pred),bins=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mean Absolute Error:',metrics.mean_absolute_error(y_test,y_pred))\nprint('Root mean Squared Error:',np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\nprint('R2 Score:',metrics.r2_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fitting the RANDOM FOREST REGRESSION TO THE DATASET\n\nfrom sklearn.ensemble import RandomForestRegressor\nregressor=RandomForestRegressor(n_estimators=300,random_state=0)\nregressor.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=regressor.predict(X_test)\nplt.scatter(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot((y_test-y_pred),bins=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mean Absolute Error:',metrics.mean_absolute_error(y_test,y_pred))\nprint('Root mean Squared Error:',np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\nprint('R2 Score:',metrics.r2_score(y_test,y_pred))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}